{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.layers import * \n",
    "from tensorflow.keras.optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def couple_convs(input_tensor, filter_size, kernel_size, stride = 1,\n",
    "                 padding = \"same\",kernel_initializer='he_normal' , \n",
    "                 activation = \"relu\", batch_normalize = False):\n",
    "    \n",
    "    output = Conv2D(filters=filter_size, padding=padding, \n",
    "                    kernel_initializer=kernel_initializer,\n",
    "                    kernel_size=kernel_size, strides=stride)(input_tensor) \n",
    "    \n",
    "    if batch_normalize: \n",
    "        output = BatchNormalization()(output)\n",
    "    \n",
    "    output = Activation(activation)(output)\n",
    "    \n",
    "    output = Conv2D(filters=filter_size, padding=padding, \n",
    "                    kernel_initializer=kernel_initializer,\n",
    "                    kernel_size=kernel_size, strides=stride)(output) \n",
    "    \n",
    "    if batch_normalize: \n",
    "        output = BatchNormalization()(output)\n",
    "    \n",
    "    output = Activation(activation)(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor1 = Input((572,572,1))\n",
    "filter_size = 64\n",
    "#### cnotraction path ##############\n",
    "######### increasing the what and decreasing the where ############\n",
    "cv1= couple_convs(input_tensor=input_tensor1,\n",
    "                  filter_size=filter_size, \n",
    "                  padding = \"valid\",\n",
    "                  kernel_size=(3,3),batch_normalize=True) \n",
    "pool1 = MaxPool2D(pool_size=2, strides=2)(cv1)\n",
    "drop1 = Dropout(0.2)(pool1)\n",
    "\n",
    "cv2= couple_convs(input_tensor=drop1,\n",
    "                  filter_size=filter_size*2, \n",
    "                  padding = \"valid\",\n",
    "                  kernel_size=(3,3),batch_normalize=True) \n",
    "pool2 = MaxPool2D(pool_size=2, strides=2)(cv2)\n",
    "drop2 = Dropout(0.2)(pool2)\n",
    "\n",
    "cv3= couple_convs(input_tensor=drop2,\n",
    "                  filter_size=filter_size*4, \n",
    "                  padding = \"valid\",\n",
    "                  kernel_size=(3,3),batch_normalize=True) \n",
    "pool3 = MaxPool2D(pool_size=2, strides=2)(cv3)\n",
    "drop3 = Dropout(0.2)(pool3)\n",
    "\n",
    "cv4= couple_convs(input_tensor=drop3,\n",
    "                  filter_size=filter_size*8, \n",
    "                  padding = \"valid\",\n",
    "                  kernel_size=(3,3),batch_normalize=True) \n",
    "pool4 = MaxPool2D(pool_size=2, strides=2)(cv4)\n",
    "drop4 = Dropout(0.2)(pool4)\n",
    "\n",
    "cv5= couple_convs(input_tensor=drop4,\n",
    "                  filter_size=filter_size*16, \n",
    "                  padding = \"valid\",\n",
    "                  kernel_size=(3,3),batch_normalize=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dropout_29/cond/Merge:0' shape=(?, 32, 32, 512) dtype=float32>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# expanding path ################## \n",
    "cropped_cv4 = Cropping2D(cropping=(4,4))(cv4)\n",
    "pool5 = UpSampling2D(size =(2,2))(cv5) \n",
    "cv6 = Conv2D(filters=filter_size*8, kernel_size=2, activation ='relu', \n",
    "             padding = 'same', kernel_initializer = 'he_normal')(pool5)\n",
    "merge6 = concatenate([cropped_cv4,cv6],axis=3)\n",
    "cv6= couple_convs(input_tensor=merge6,\n",
    "                  filter_size=filter_size*8, \n",
    "                  padding = \"valid\",\n",
    "                  kernel_size=(3,3),batch_normalize=True) \n",
    "pool6 = UpSampling2D(size =(2,2))(cv6) \n",
    "drop6 = Dropout(0.2)(pool6)\n",
    "\n",
    "\n",
    "cropped_cv3 = Cropping2D(cropping=(16,16))(cv3)\n",
    "\n",
    "merge7 = concatenate([cropped_cv3,drop6],axis=3)\n",
    "cv7= couple_convs(input_tensor=merge7,\n",
    "                  filter_size=filter_size*8, \n",
    "                  padding = \"valid\",\n",
    "                  kernel_size=(3,3),batch_normalize=True) \n",
    "pool7 = UpSampling2D(size =(2,2))(cv7) \n",
    "drop7 = Dropout(0.2)(pool7)\n",
    "\n",
    "cropped_cv2 = Cropping2D(cropping=(40,40))(cv2)\n",
    "merge8 = concatenate([cropped_cv2,drop7],axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'activation_76/Relu:0' shape=(?, 52, 52, 512) dtype=float32>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
